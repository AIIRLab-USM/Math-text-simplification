from evaluate import load

sari = load('sari')

def evaluate_simplification_with_sari(source: str, references: list[str], hypothesis: str) -> float:
    """
    Evaluate the simplification using the SARI metric.
    
    Args:
        source (str): The source sentence.
        references (List[str]): The reference sentences (generated by humans in the dataset).
        hypothesis (str): The simplified sentence.
    
    Returns:
        float: The SARI score.
    """
    results = sari.compute(predictions=[hypothesis], references=[references], sources=[source])
    score: float = results['sari'] # type: ignore
    return score

def evaluate_simplification_with_flesch_kincaid(source: str, references: list[str], hypothesis: str) -> float:
    """
    Evaluate the simplification using the Flesch-Kincaid readability score.
    
    Args:
        source (str): The source sentence.
        references (List[str]): The reference sentences (generated by humans in the dataset).
        hypothesis (str): The simplified sentence.
    
    Returns:
        float: The Flesch-Kincaid score of the hypothesis.
    """
    from textstat import flesch_kincaid_grade # type: ignore
    # Calculate the Flesch-Kincaid grade level for the hypothesis
    score = flesch_kincaid_grade(hypothesis)
    # Calculate the Flesch-Kincaid grade level for the source
    source_score = flesch_kincaid_grade(source)
    return score - source_score  # Return the difference to see how much easier the hypothesis is compared to the source

from llm_simplifier import simplify_math_text
from llm_definitions import get_definitions

def evaluate_simplification_with_llm(source: str, references: list[str]) -> tuple[float, float]:
    """
    Evaluate the simplification using the LLM to generate a simplified sentence.
    
    Args:
        source (str): The source sentence.
        references (List[str]): The reference sentences (generated by humans in the dataset).
    
    Returns:
        float: The SARI score of the LLM-generated simplification.
    """
    definitions = get_definitions(source)
    hypothesis = simplify_math_text(source, definitions)
    return (evaluate_simplification_with_sari(source, references, hypothesis), evaluate_simplification_with_flesch_kincaid(source, references, hypothesis))

def main(args=None):
    # Load csv file with Text and Simplified columns
    import pandas as pd
    import argparse
    parser = argparse.ArgumentParser(description="Evaluate the simplification of math text using SARI metric.")
    parser.add_argument('csv_file', type=str, help='Path to the CSV file containing the text and simplified columns.')
    parser.add_argument('--source_col', type=str, default='Text', help='Column name for the source text.')
    parser.add_argument('--simplified_col', type=str, default='Simplified', help='Column name for the simplified text.')
    args = parser.parse_args(args)
    df = pd.read_csv(args.csv_file)
    if args.source_col not in df.columns or args.simplified_col not in df.columns:
        raise ValueError(f"Columns {args.source_col} and {args.simplified_col} must be present in the CSV file.")
    total_score = 0.0
    for index, row in df.iterrows():
        source = row[args.source_col]
        references = row[args.simplified_col].split(';')
        score = evaluate_simplification_with_llm(source, references) # type: ignore
        total_score += score[0]
        print(f"Row {index}: SARI score = {score[0]:.4f}, Flesch-Kincaid score = {score[1]:.4f}")
    average_score = total_score / len(df)
    print(f"Average SARI score: {average_score:.4f}")
if __name__ == "__main__":
    main()